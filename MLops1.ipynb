{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ed09ce",
   "metadata": {},
   "source": [
    "# MLOps, or Machine Learning Operations, is an essential framework that merges machine learning (ML), DevOps, and data engineering practices. Its primary goal is to ensure that ML models can be deployed, managed, and scaled in production environments in a reliable and efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f643d",
   "metadata": {},
   "source": [
    "#What Does MLOps Do?\n",
    "MLOps provides organizations with several key benefits:\n",
    "\n",
    "Automation and Streamlining: It automates and streamlines the entire ML lifecycle, from data collection to model deployment.\n",
    "Reproducibility and Scalability: MLOps ensures that ML models are reproducible, scalable, and continuously monitored for performance.\n",
    "Enhanced Collaboration: It fosters better collaboration between data scientists and operations teams, breaking down silos and improving communication.\n",
    "Model Management: MLOps facilitates effective management of model versioning, testing, deployment, and retraining processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd248f38",
   "metadata": {},
   "source": [
    "#Key Steps in the MLOps Workflow\n",
    "The MLOps workflow typically involves several critical steps:\n",
    "\n",
    "Data Collection & Preparation: Gathering and preprocessing data to ensure it is suitable for training.\n",
    "Model Development & Training: Building and training machine learning models using the prepared data.\n",
    "Model Validation & Testing: Evaluating the model's performance to ensure it meets the required standards.\n",
    "Model Deployment to Production: Deploying the validated model into a production environment where it can be used for real-time predictions.\n",
    "Monitoring & Performance Tracking: Continuously monitoring the model's performance to detect any issues or degradation.\n",
    "Model Maintenance & Retraining: Regularly updating and retraining the model to maintain its accuracy and relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52606ca0",
   "metadata": {},
   "source": [
    "#How MLOps Works\n",
    "MLOps integrates various tools and pipelines to enhance the ML process:\n",
    "\n",
    "Automation of Repetitive Tasks: It automates repetitive tasks associated with machine learning, freeing up time for data scientists to focus on more complex problems.\n",
    "CI/CD for Models: MLOps employs Continuous Integration and Continuous Deployment (CI/CD) practices to ensure that models can be updated and deployed seamlessly.\n",
    "Real-Time Monitoring: It enables real-time monitoring of data and model performance, allowing for quick responses to any issues.\n",
    "Triggering Retraining: If a model's performance drops below a certain threshold, MLOps can automatically trigger retraining to improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11804f4",
   "metadata": {},
   "source": [
    "#Uses of MLOps\n",
    "MLOps has a wide range of applications across various industries, including:\n",
    "\n",
    "Fraud Detection in Finance: Identifying fraudulent transactions in real-time to protect financial institutions and their customers.\n",
    "Predictive Maintenance in Manufacturing: Anticipating equipment failures before they occur, reducing downtime and maintenance costs.\n",
    "Customer Behavior Modeling in Marketing: Analyzing customer data to tailor marketing strategies and improve engagement.\n",
    "Recommendation Systems in E-Commerce: Providing personalized product recommendations to enhance the shopping experience.\n",
    "Real-Time Decision Making in Healthcare: Supporting healthcare professionals with data-driven insights for timely decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1809814",
   "metadata": {},
   "source": [
    "# MLOps is a vital practice that enhances the efficiency and effectiveness of machine learning initiatives, enabling organizations to leverage data-driven insights in a scalable and sustainable manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba708b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b61a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Loads NumPy, a tool to work with numbers and arrays.\n",
    "from sklearn.datasets import make_classification #Lets you create a fake dataset for testing machine learning.\n",
    "from sklearn.model_selection import train_test_split #Splits your data into training and testing parts.\n",
    "from sklearn.linear_model import LogisticRegression #Brings in a simple model used for classification (Logistic Regression)\n",
    "from sklearn.ensemble import RandomForestClassifier #Loads a strong model that uses many decision trees (Random Forest).\n",
    "from xgboost import XGBClassifier #XGBoost (Extreme Gradient Boosting) is an efficient, scalable gradient boosting library that often performs very well in classification problems.\n",
    "from sklearn.metrics import classification_report #To print a report showing the precision, recall, F1-score, and support for each class — useful for evaluating classification models.\n",
    "import warnings #Hides warning messages so the output looks cleaner.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "475f44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line creates fake data for a classification problem (two classes: 0 and 1).\n",
    "#It makes the data imbalanced:\n",
    "#90% of the samples belong to class 0,\n",
    "#10% belong to class 1.\n",
    "x,y = make_classification(n_samples=1000,n_features=10,n_informative=2,n_redundant=8,weights=[0.9,0.1],flip_y=0,random_state=42)\n",
    "#Key parameters explained:\n",
    "#n_samples=1000: Create 1000 rows of data.\n",
    "#n_features=10: Each row has 10 features (columns).#n_informative=2: Only 2 features actually affect the output.\n",
    "#n_redundant=8: Other 8 features are just noise (not useful).\n",
    "#weights=[0.9, 0.1]: Make 90% class 0 and 10% class 1.\n",
    "#flip_y=0: No random noise added to the labels.\n",
    "#random_state=42: For reproducibility (same result every time).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07b0cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y,return_counts=True)\n",
    "#It shows how many samples are in each class (0 and 1).\n",
    "#np.unique() finds the unique values in y (your target labels).\n",
    "#return_counts=True also returns how many times each class appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f686c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8c58343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       270\n",
      "           1       0.82      0.60      0.69        30\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.89      0.79      0.83       300\n",
      "weighted avg       0.94      0.95      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This code trains a Logistic Regression model on your dataset and checks how well it performs using a detailed report.\n",
    "#defining model hyperparameters\n",
    "params = {\"solver\":\"lbfgs\",\"max_iter\":1000,\"multi_class\":\"auto\",\"random_state\":42,}\n",
    "#train model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "#predict based on test set \n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "#making report\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3c56b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9568345323741008,\n",
       "  'recall': 0.9851851851851852,\n",
       "  'f1-score': 0.9708029197080292,\n",
       "  'support': 270.0},\n",
       " '1': {'precision': 0.8181818181818182,\n",
       "  'recall': 0.6,\n",
       "  'f1-score': 0.6923076923076923,\n",
       "  'support': 30.0},\n",
       " 'accuracy': 0.9466666666666667,\n",
       " 'macro avg': {'precision': 0.8875081752779594,\n",
       "  'recall': 0.7925925925925925,\n",
       "  'f1-score': 0.8315553060078608,\n",
       "  'support': 300.0},\n",
       " 'weighted avg': {'precision': 0.9429692609548727,\n",
       "  'recall': 0.9466666666666667,\n",
       "  'f1-score': 0.9429533969679956,\n",
       "  'support': 300.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict = classification_report(y_test,y_pred,output_dict=True)\n",
    "report_dict\n",
    "#Instead of printing the report as text, this makes the report return as a Python dictionary.\n",
    "#This dictionary (report_dict) contains all the metrics like precision, recall, f1-score, support for each class, plus averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b8e8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLflow is a valuable tool for managing machine learning workflows. Here are its key benefits:\n",
    "\n",
    "#Tracking Experiments: Log and save settings and results for each model you try.\n",
    "#Logging Metrics: Keep track of model performance metrics for easy evaluation.\n",
    "#aving Models: Store trained models for future reuse without retraining.\n",
    "#Easy Comparison: Compare multiple runs side by side to identify the best model.\n",
    "#Deployment Support: Convert models into APIs for easy sharing and integration.\n",
    "#Overall, MLflow streamlines the process of experimenting, tracking, and deploying machine learning models.\n",
    "\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6320386",
   "metadata": {},
   "source": [
    "#The code snippet shows how to use MLflow to track a machine learning experiment. It starts by naming the experiment \"1st Experiment\" with mlflow.set_experiment(), which helps keep different experiments organized. Then, it connects to a local MLflow tracking server at http://127.0.0.1:5000/ using mlflow.set_tracking_uri(), ensuring that all the logged information goes to the right place. Inside a block created by mlflow.start_run(), the code logs the parameters used for training the model with mlflow.log_params(), making it easy to refer back to them later. It also records important performance metrics like accuracy and recall using mlflow.log_metrics(), which helps assess how well the model performed. Finally, the trained logistic regression model is saved with mlflow.sklearn.log_model(), so it can be reused or deployed in the future. Overall, this code effectively organizes and captures essential details about the experiment, making it easier to manage and compare different machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c330f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/22 11:26:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/22 11:26:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run kindly-eel-107 at: http://127.0.0.1:5000/#/experiments/357739066966589436/runs/07776131e3a24dcfbeee28c0d3501ba9\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/357739066966589436\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"1st Experiment\")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")\n",
    "#mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'recall_class_0': report_dict['0']['recall'],\n",
    "        'recall_class_1': report_dict['1']['recall'],\n",
    "        'f1_score_macro': report_dict['macro avg']['f1-score']\n",
    "    })\n",
    "    mlflow.sklearn.log_model(lr, \"Logistic Regression\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
